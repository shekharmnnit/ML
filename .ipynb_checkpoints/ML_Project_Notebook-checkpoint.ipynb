{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T01:01:23.063406200Z",
     "start_time": "2023-11-28T01:01:22.908133Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPj4nfzkD-D4",
    "outputId": "96982e02-eac4-4802-ebaa-187ee8a3f51e"
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m trainDatasetfilePath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/shekharmnnit/ML/main/Customer\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Churn\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Dataset/customer_churn_dataset-training-master.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m testDatasetPath\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/shekharmnnit/ML/main/Customer\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Churn\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Dataset/customer_churn_dataset-testing-master.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m training_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(trainDatasetfilePath)\n\u001b[0;32m      9\u001b[0m testing_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(testDatasetPath)\n\u001b[0;32m     11\u001b[0m training_df \u001b[38;5;241m=\u001b[39m training_df\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerID\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    713\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    717\u001b[0m     path_or_buf,\n\u001b[0;32m    718\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    719\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    720\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    721\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    725\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    367\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    369\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:270\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "trainDatasetfilePath = 'https://raw.githubusercontent.com/shekharmnnit/ML/main/Customer%20Churn%20Dataset/customer_churn_dataset-training-master.csv'\n",
    "testDatasetPath= 'https://raw.githubusercontent.com/shekharmnnit/ML/main/Customer%20Churn%20Dataset/customer_churn_dataset-testing-master.csv'\n",
    "training_df = pd.read_csv(trainDatasetfilePath)\n",
    "testing_df = pd.read_csv(testDatasetPath)\n",
    "\n",
    "training_df = training_df.drop(columns = 'CustomerID')\n",
    "newColumnNames = {col : col.replace(' ','_') for col in training_df.columns}\n",
    "training_df = training_df.rename(columns = newColumnNames)\n",
    "\n",
    "testing_df = testing_df.drop(columns = 'CustomerID')\n",
    "newColumnNames = {col : col.replace(' ','_') for col in testing_df.columns}\n",
    "testing_df = testing_df.rename(columns = newColumnNames)\n",
    "\n",
    "print(\"----Training Data set----------\")\n",
    "print(training_df.head(5).to_string())\n",
    "print(f\"Number of observation in training dataset: {training_df.shape[0]}\")\n",
    "print(\"Null value count\")\n",
    "print(training_df.isna().sum())\n",
    "print(f\"Training: Total number of rows with null value = {training_df.isna().sum().sum()}\")\n",
    "\n",
    "print(\"----Testing Data set----------\")\n",
    "print(testing_df.head(5).to_string())\n",
    "print(f\"Number of observation in test dataset: {testing_df.shape[0]}\")\n",
    "print(\"Null value count\")\n",
    "print(testing_df.isna().sum())\n",
    "print(f\"Testing: Total number of rows with null value = {testing_df.isna().sum().sum()}\")\n",
    "\n",
    "print('-------------------Train Data cleaning-------------------')\n",
    "print(training_df[training_df['Age'].isna()].to_string()) # row detail with na value\n",
    "print(\"199295 row has null value for all the columns, so removing 199295\")\n",
    "training_df = training_df.drop(training_df[training_df['Age'].isna()].index)\n",
    "print(training_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T23:05:52.244595500Z",
     "start_time": "2023-11-26T23:05:52.241498600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yithbw2REE_x",
    "outputId": "3cf74255-6743-4bbb-e95e-8ccfea3ec5f5"
   },
   "outputs": [],
   "source": [
    "training_df.duplicated().sum()\n",
    "testing_df.duplicated().sum()\n",
    "print(f\"Train data duplicated= {training_df.duplicated().sum()}\")\n",
    "print(f\"Test data duplicated= {testing_df.duplicated().sum()}\")\n",
    "print(\"no need to remove duplicate data as duplicate data is 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.242498500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivd9OqtSGGDW",
    "outputId": "a7c9b1ab-ac4b-4b1b-ee6c-8b1cd03d77e5"
   },
   "outputs": [],
   "source": [
    "# Down sampling\n",
    "# Calculate the proportions of classes\n",
    "train_class_distribution = training_df['Churn'].value_counts()\n",
    "print(\"Churn of Train data\")\n",
    "print(train_class_distribution)\n",
    "test_class_distribution = testing_df['Churn'].value_counts()\n",
    "print('Churn of test data')\n",
    "print(test_class_distribution)\n",
    "\n",
    "train_proportion_0 = train_class_distribution.get(0, 0) / len(training_df['Churn'])\n",
    "train_proportion_1 = train_class_distribution.get(1, 0) / len(training_df['Churn'])\n",
    "test_proportion_0 = test_class_distribution.get(0, 0) / len(testing_df['Churn'])\n",
    "test_proportion_1 = test_class_distribution.get(1, 0) / len(testing_df['Churn'])\n",
    "print(f'train-churn-0=   {train_proportion_0.round(2)}\\n train-churn-1=  {train_proportion_1.round(2)}\\n test-churn-0=   {test_proportion_0.round(2)}\\n test-churn-1=   {test_proportion_1.round(2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.243498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "tNqih3k3GHdV",
    "outputId": "dfdf12d1-b8c8-4a88-b7ce-b806fc375feb"
   },
   "outputs": [],
   "source": [
    "# traning data count plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.countplot(data=training_df, x=\"Churn\")\n",
    "\n",
    "# You can customize the plot further\n",
    "plt.title(\"traning- Churn Count Plot\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T23:05:52.244595500Z",
     "start_time": "2023-11-26T23:05:52.244595500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "NbuMD4E9GJVR",
    "outputId": "d073db6b-db55-419d-c0a2-ed88c4293ca1"
   },
   "outputs": [],
   "source": [
    "# remove observation train\n",
    "churn_1_rows = training_df[training_df['Churn'] == 1]\n",
    "random_sample = churn_1_rows.sample(n=59166, random_state=5508)\n",
    "training_df = training_df.drop(random_sample.index)\n",
    "\n",
    "\n",
    "\n",
    "# traning data count plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.countplot(data=training_df, x=\"Churn\")\n",
    "plt.title(\"traning- Churn Count Plot\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.245598400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "Eqdq9pIEGMCs",
    "outputId": "4d86e439-f26c-4696-a856-8751ac42eeff"
   },
   "outputs": [],
   "source": [
    "# test data count plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.countplot(data=testing_df, x=\"Churn\")\n",
    "\n",
    "# You can customize the plot further\n",
    "plt.title(\"testing- Churn Count Plot\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.245598400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "CzIll-zIGNV5",
    "outputId": "440a8170-ea6e-4ca6-be02-6001ffe03777"
   },
   "outputs": [],
   "source": [
    "# remove observation from test\n",
    "churn_1_rows = testing_df[testing_df['Churn'] == 0]\n",
    "random_sample = churn_1_rows.sample(n=3388, random_state=5508)\n",
    "testing_df = testing_df.drop(random_sample.index)\n",
    "\n",
    "# traning data count plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.countplot(data=testing_df, x=\"Churn\")\n",
    "\n",
    "# You can customize the plot further\n",
    "plt.title(\"traning- Churn Count Plot\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T23:05:52.285598100Z",
     "start_time": "2023-11-26T23:05:52.246599100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DugwDPMXGOqR",
    "outputId": "b8a3dc6f-755a-427d-9570-117d70450d19"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your dataset is stored in a variable named 'df'\n",
    "# Features to be checked for outliers\n",
    "# features = ['Age', 'Tenure', 'Usage Frequency', 'Support Calls', 'Payment Delay', 'Total Spend']\n",
    "\n",
    "# Create subplots for each feature\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i,feature in enumerate(['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']):\n",
    "     # Adjust the figure size as needed\n",
    "    plt.subplot(1,7,i+1)\n",
    "    sns.boxplot(x=training_df[feature])\n",
    "    # plt.title(f'Boxplot for {feature}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.247598100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6oiZsd-UGP9E",
    "outputId": "fac814e2-beba-4296-9f7c-e9220705415c"
   },
   "outputs": [],
   "source": [
    "# Create combine subplots for each feature\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i,feature in enumerate(['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']):\n",
    "     # Adjust the figure size as needed\n",
    "    plt.subplot(1,7,i+1)\n",
    "    sns.boxplot(training_df,x='Churn',y=feature)\n",
    "    # plt.title(f'Boxplot for {feature}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.248598200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "OSOY5hIDGRYw",
    "outputId": "06482662-77a5-477a-9990-05b0d11a13d6"
   },
   "outputs": [],
   "source": [
    "# Covariance Matrix display\n",
    "def Standardized(dataframe):\n",
    "    return (dataframe - dataframe.mean()) / dataframe.std()\n",
    "encodingTrainDFForHitmap = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTrainDfForHitmap= Standardized(encodingTrainDFForHitmap[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTrainDfForHitmap=pd.concat([standardizedTrainDfForHitmap,encodingTrainDFForHitmap[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly','Churn']]], axis=1)\n",
    "\n",
    "covariance_matrix = standardizedTrainDfForHitmap.cov()\n",
    "# plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(covariance_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Sample Covariance Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.249597900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "nrggX0rYGSqD",
    "outputId": "f8367039-8776-44d9-f9a4-fdcececc88b8"
   },
   "outputs": [],
   "source": [
    "# Correlation coefficients Matrix\n",
    "Correlation_matrix = standardizedTrainDfForHitmap.corr()\n",
    "# plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(Correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Sample Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.250597900Z"
    },
    "id": "8UdprprWGeEa"
   },
   "outputs": [],
   "source": [
    "# Random Forest Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "# def Standardized(dataframe):\n",
    "#     return (dataframe - dataframe.mean()) / dataframe.std()\n",
    "\n",
    "encodingTrainDF = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTrainDf= Standardized(encodingTrainDF[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTrainDf=pd.concat([standardizedTrainDf,encodingTrainDF[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "\n",
    "# X_train= standardizedTrainDf.drop(columns=['Churn'])\n",
    "X_train = standardizedTrainDf\n",
    "# X_train = sm.add_constant(X_train)\n",
    "y_train = training_df['Churn']\n",
    "\n",
    "\n",
    "encodingTestDF = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTestDf= Standardized(encodingTestDF[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTestDf=pd.concat([standardizedTestDf,encodingTestDF[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "\n",
    "X_test= standardizedTestDf\n",
    "# X_test = sm.add_constant(X_test)\n",
    "y_test = testing_df['Churn']\n",
    "\n",
    "# print(X_test.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.251598100Z"
    },
    "id": "C8Cg52qAGgQS"
   },
   "outputs": [],
   "source": [
    "# building RandomForestRegressor model\n",
    "rf= RandomForestRegressor(random_state=5805)\n",
    "rf.fit(X_train,y_train)\n",
    "featureImportancs= rf.feature_importances_\n",
    "\n",
    "indices= np.argsort(featureImportancs)\n",
    "sortedFeatureImportancs = featureImportancs[indices]\n",
    "sortedFeatureName= X_train.columns[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.253598Z"
    },
    "id": "AStjWSqiGh7h"
   },
   "outputs": [],
   "source": [
    "# building RandomForestRegressor model\n",
    "# plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(range(sortedFeatureImportancs.size), sortedFeatureImportancs)\n",
    "plt.yticks(range(sortedFeatureName.size), sortedFeatureName)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance vs Feature')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.254597500Z"
    },
    "id": "uo-3tocBHFQw"
   },
   "outputs": [],
   "source": [
    "# building RandomForestRegressor model\n",
    "threshold= 0.0015\n",
    "selectedFeatures = [sortedFeatureName[i] for i, importance in enumerate(sortedFeatureImportancs) if importance >= threshold]\n",
    "eliminatedFeatures = [sortedFeatureName[i] for i,importance in enumerate(sortedFeatureImportancs) if importance < threshold]\n",
    "for i,j in enumerate(sortedFeatureName):\n",
    "  print(f'{j}= {sortedFeatureImportancs[i].round(4)}')\n",
    "print(\"selected features= \", selectedFeatures)\n",
    "print(\"eliminated Features= \", eliminatedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.254597500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0z1FjHNHIbb",
    "outputId": "cfd9de34-187f-4eda-bdb8-67e60c2e0042"
   },
   "outputs": [],
   "source": [
    "# PCA-Principal Component Analysis\n",
    "# X_train is standardized\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "pcaDatasetDF=copy.deepcopy(X_train)\n",
    "pcaDatasetDF = pcaDatasetDF.astype(np.float64)\n",
    "print(f'original data conditional number={np.linalg.cond(pcaDatasetDF)}')\n",
    "pca=PCA()\n",
    "pca.fit(pcaDatasetDF)\n",
    "pcaCoordinate=pca.transform(pcaDatasetDF)\n",
    "EVR= pca.explained_variance_ratio_\n",
    "CVR = np.cumsum(EVR) # cumulative explained variance\n",
    "numComponents = np.argmax(CVR >= 0.95) +1\n",
    "print(\"number of Principal Component = \"+ str(numComponents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.255597700Z"
    },
    "id": "qkNYVEYCNa0U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.256597900Z"
    },
    "id": "VZnsuYQ8HJvq"
   },
   "outputs": [],
   "source": [
    "# PCA-Principal Component Analysis\n",
    "pca=PCA(numComponents)\n",
    "pca.fit(pcaDatasetDF)\n",
    "pcaCoordinate=pca.transform(pcaDatasetDF)\n",
    "# print(pcaCoordinate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.257598200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Hos0e5FHLIK",
    "outputId": "f035f9ff-da2e-439f-b3b9-6561eb01b8e7"
   },
   "outputs": [],
   "source": [
    "# PCA-Principal Component Analysis\n",
    "newPCAdf = pd.DataFrame(pcaCoordinate)\n",
    "# print(newPCAdf.shape[1])\n",
    "newColumnNames = {col : 'Component-'+ str(col+1) for col in newPCAdf.columns}\n",
    "newPCAdf = newPCAdf.rename(columns = newColumnNames)\n",
    "print(f'transform data conditional number={np.linalg.cond(newPCAdf)}')\n",
    "print(newPCAdf.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.258597900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "FjZcjLWOHL60",
    "outputId": "954020cc-ff8e-48e5-ba42-fc7df2bf8bf9"
   },
   "outputs": [],
   "source": [
    "# PCA-Principal Component Analysis\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(np.arange(1, pcaDatasetDF.shape[1]+ 1), CVR, marker='o')\n",
    "# plt.xlabel('Number of Features')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.arange(1, pcaDatasetDF.shape[1]+ 1), CVR, marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.95, color='red', label='95% Threshold')\n",
    "plt.axvline(x=numComponents, color='green', label=f'{numComponents} Features')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.259598200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUvBagnJHNh1",
    "outputId": "79e7c7f6-f7ba-4269-e174-c4b950f5481b"
   },
   "outputs": [],
   "source": [
    "# SVD-Singular Value Decomposition Analysis\n",
    "# X_train is standardized\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svdDatasetDF=copy.deepcopy(X_train)\n",
    "svd=TruncatedSVD(svdDatasetDF.shape[1])\n",
    "svd.fit(svdDatasetDF)\n",
    "svdCoordinate=svd.transform(svdDatasetDF)\n",
    "\n",
    "EVR= svd.explained_variance_ratio_\n",
    "CVR = np.cumsum(EVR) # cumulative explained variance\n",
    "numComponents = np.argmax(CVR >= 0.95)+1\n",
    "print(\"number of Component = \"+ str(numComponents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.260598300Z"
    },
    "id": "icnkJZDiHOqK"
   },
   "outputs": [],
   "source": [
    "# SVD-Singular Value Decomposition Analysis\n",
    "svd=TruncatedSVD(numComponents)\n",
    "svd.fit(svdDatasetDF)\n",
    "svdCoordinate=svd.transform(svdDatasetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.261597900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQJpdq7KHPlQ",
    "outputId": "f56b286c-37ac-4c0d-982f-08635231d863"
   },
   "outputs": [],
   "source": [
    "# SVD-Singular Value Decomposition Analysis\n",
    "\n",
    "newSVDdf = pd.DataFrame(svdCoordinate)\n",
    "newColumnNames = {col: 'Component-' + str(col + 1) for col in newSVDdf.columns}\n",
    "newSVDdf = newSVDdf.rename(columns=newColumnNames)\n",
    "print(newSVDdf.head().to_string())\n",
    "\n",
    "# df_svd = pd.DataFrame(pcaCoordinate, columns=[f'Component_{i+1}' for i in range(pcaCoordinate.shape[1])])\n",
    "# print(df_svd.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.263598100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "Z6wS-OMNHQc_",
    "outputId": "1506cec5-351e-47fa-d4d4-3ed27a3928e4"
   },
   "outputs": [],
   "source": [
    "# SVD-Singular Value Decomposition Analysis\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(np.arange(1, newSVDdf.shape[1]+ 1), CVR, marker='o')\n",
    "# plt.xlabel('Number of Features')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.arange(1, svdDatasetDF.shape[1]+ 1), CVR, marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.95, color='red', label='95% Threshold')\n",
    "plt.axvline(x=numComponents, color='green', label=f'{numComponents} Features')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.264598100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XujDP_mHS6D",
    "outputId": "c1bbcbd1-3b0b-4f91-ba6a-11303f741543"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' containing your dataset\n",
    "# Select the features for which you want to calculate VIF\n",
    "# Exclude non-numeric columns and the target variable 'Churn'\n",
    "\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "p_train = X_train.astype(int)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = p_train.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(p_train.values, i) for i in range(p_train.shape[1])]\n",
    "\n",
    "# Sort the features by VIF in descending order\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the VIF values\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.264598100Z"
    },
    "id": "raIuK-h2Yfby"
   },
   "outputs": [],
   "source": [
    "# Print the VIF values\n",
    "# print(vif_data[Feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.265598200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "tGO4FJCUHq65",
    "outputId": "38ef5bb9-26d2-49f5-9145-ec401fe1c097"
   },
   "outputs": [],
   "source": [
    "# VIF\n",
    "# plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(range(vif_data['VIF'].size), vif_data['VIF'])\n",
    "plt.yticks(range(vif_data['Feature'].size), vif_data['Feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance vs Feature')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.266598100Z"
    },
    "id": "F--U7YCfHr_u"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "OLSencodingTrainDF = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "OLSstandardizedTrainDf= Standardized(OLSencodingTrainDF[{'Age','Tenure','Usage_Frequency','Payment_Delay','Last_Interaction','Total_Spend'}])\n",
    "OLSstandardizedTrainDf=pd.concat([OLSstandardizedTrainDf,OLSencodingTrainDF[{'Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly','Churn'}]], axis=1)\n",
    "\n",
    "# X_train= standardizedTrainDf.drop(columns=['Churn'])\n",
    "X_train_ols = OLSstandardizedTrainDf\n",
    "# X_train = sm.add_constant(X_train)\n",
    "y_train_ols = Standardized(training_df['Support_Calls'])\n",
    "\n",
    "\n",
    "OLSencodingTestDF = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "OLSstandardizedTestDf= Standardized(OLSencodingTestDF[{'Age','Tenure','Usage_Frequency','Payment_Delay','Last_Interaction','Total_Spend'}])\n",
    "OLSstandardizedTestDf=pd.concat([OLSstandardizedTestDf,OLSencodingTestDF[{'Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly','Churn'}]], axis=1)\n",
    "\n",
    "X_test_ols= OLSstandardizedTestDf\n",
    "y_test_ols = Standardized(testing_df['Support_Calls'])\n",
    "\n",
    "# add const\n",
    "X_train_ols = sm.add_constant(X_train_ols)\n",
    "X_test_ols = sm.add_constant(X_test_ols)\n",
    "\n",
    "# print(X_train_ols.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.267598Z"
    },
    "id": "fjiD8A5Qkpc3"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "results = pd.DataFrame(columns=['Features', 'AIC', 'BIC', 'Adj_R2', 'P-value'])\n",
    "import statsmodels.api as sm\n",
    "OLSmodel = sm.OLS(y_train_ols,X_train_ols).fit()\n",
    "results = results.append({'Features': OLSmodel.pvalues.idxmax(),\n",
    "      'AIC': OLSmodel.aic,\n",
    "      'BIC': OLSmodel.bic,\n",
    "      'Adj_R2': OLSmodel.rsquared_adj,\n",
    "      'P-value': OLSmodel.pvalues.max()}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.268597900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g81XbJMpp9mC",
    "outputId": "ac7620af-4729-4109-de93-6323b4d5e31c"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "print(OLSmodel.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.269598500Z"
    },
    "id": "N_71gkfqqQKH"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "# drop\n",
    "X_train_ols= X_train_ols.drop(columns=['Subscription_Type_Premium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.270598900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8aJLwA581n8C",
    "outputId": "befcbf29-5b45-432c-88bd-a1533a829fb3"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "OLSmodel = sm.OLS(y_train_ols,X_train_ols).fit()\n",
    "results = results.append({'Features': OLSmodel.pvalues.idxmax(),\n",
    "      'AIC': OLSmodel.aic,\n",
    "      'BIC': OLSmodel.bic,\n",
    "      'Adj_R2': OLSmodel.rsquared_adj,\n",
    "      'P-value': OLSmodel.pvalues.max()}, ignore_index=True)\n",
    "print(OLSmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.271598200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEIFmH5Z2IFj",
    "outputId": "39b927b2-2ffb-4df3-a903-3e63c3f22622"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "X_train_ols= X_train_ols.drop(columns=['Subscription_Type_Standard'])\n",
    "OLSmodel = sm.OLS(y_train_ols,X_train_ols).fit()\n",
    "results = results.append({'Features': OLSmodel.pvalues.idxmax(),\n",
    "      'AIC': OLSmodel.aic,\n",
    "      'BIC': OLSmodel.bic,\n",
    "      'Adj_R2': OLSmodel.rsquared_adj,\n",
    "      'P-value': OLSmodel.pvalues.max()}, ignore_index=True)\n",
    "print(OLSmodel.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.272598200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vb7b10Ly-wHT",
    "outputId": "9c2b7559-540f-4598-ece3-9df5ef8f0f32"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "X_train_ols= X_train_ols.drop(columns=['Contract_Length_Quarterly'])\n",
    "OLSmodel = sm.OLS(y_train_ols,X_train_ols).fit()\n",
    "results = results.append({'Features': OLSmodel.pvalues.idxmax(),\n",
    "      'AIC': OLSmodel.aic,\n",
    "      'BIC': OLSmodel.bic,\n",
    "      'Adj_R2': OLSmodel.rsquared_adj,\n",
    "      'P-value': OLSmodel.pvalues.max()}, ignore_index=True)\n",
    "print(OLSmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.273597900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxfQebxL-9Z_",
    "outputId": "a99023ff-bc3a-4d90-db7b-ff48f66e8795"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "X_train_ols= X_train_ols.drop(columns=['Tenure'])\n",
    "OLSmodel = sm.OLS(y_train_ols,X_train_ols).fit()\n",
    "results = results.append({'Features': OLSmodel.pvalues.idxmax(),\n",
    "      'AIC': OLSmodel.aic,\n",
    "      'BIC': OLSmodel.bic,\n",
    "      'Adj_R2': OLSmodel.rsquared_adj,\n",
    "      'P-value': OLSmodel.pvalues.max()}, ignore_index=True)\n",
    "print(OLSmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.274598Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Srqe6v4I_RgH",
    "outputId": "fdb50365-49f2-4a40-b6f9-7fabfe1739e8"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "X_train_ols= X_train_ols.drop(columns=['Usage_Frequency'])\n",
    "OLSmodel = sm.OLS(y_train_ols,X_train_ols).fit()\n",
    "# results = results.append({'Features': OLSmodel.pvalues.idxmax(),\n",
    "#       'AIC': OLSmodel.aic,\n",
    "#       'BIC': OLSmodel.bic,\n",
    "#       'Adj_R2': OLSmodel.rsquared_adj,\n",
    "#       'P-value': OLSmodel.pvalues.max()}, ignore_index=True)\n",
    "print(OLSmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.275611700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "act2dpPA_WsA",
    "outputId": "1f615b4a-0c3b-41e8-c590-94d0a17220b9"
   },
   "outputs": [],
   "source": [
    "# T-test analysis - OLS\n",
    "print('dropped feature')\n",
    "print(results.round(6))\n",
    "# removed dropped feature from test dataset\n",
    "X_test_ols= X_test_ols.drop(columns=results.Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.276598300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "iH8gtDjI_f4A",
    "outputId": "8e7a6bf3-4961-4717-89c6-765863bf6d5a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "OLStargetPred= OLSmodel.predict(X_test_ols)\n",
    "originalTestTaarget= testing_df['Support_Calls'] # non Standardized Target test\n",
    "\n",
    "deStandardizedTargetTest = y_test_ols * originalTestTaarget.std() + originalTestTaarget.mean()\n",
    "deStandardizedTargetPred= OLStargetPred * originalTestTaarget.std() + originalTestTaarget.mean()\n",
    "\n",
    "deStandardizedTargetTest= deStandardizedTargetTest.reset_index().drop(['index'],axis=1)\n",
    "deStandardizedTargetPred= deStandardizedTargetPred.reset_index().drop(['index'],axis=1)\n",
    "\n",
    "# plot\n",
    "plt.plot(deStandardizedTargetTest, label='Actual Sales')\n",
    "plt.plot(deStandardizedTargetPred, label='Predicted Sales')\n",
    "plt.xlabel(\"value\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.title(' Actual vs predicted')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# accuracy\n",
    "mse2 = mean_squared_error(deStandardizedTargetTest, deStandardizedTargetPred)\n",
    "print(\"Mean Squared Error:\", mse2.__round__(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVyQUlIlr1bs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.277597900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDJ-QKGir1-D",
    "outputId": "832ad237-812e-4943-d011-6f7501434b8e"
   },
   "outputs": [],
   "source": [
    "#remove to recuce load on model building\n",
    "churn_1_rows = training_df[training_df['Churn'] == 1]\n",
    "random_sample = churn_1_rows.sample(n=165833, random_state=5508)\n",
    "training_df = training_df.drop(random_sample.index)\n",
    "#remove to recuce load on model building\n",
    "churn_0_rows = training_df[training_df['Churn'] == 0]\n",
    "random_sample = churn_0_rows.sample(n=165833, random_state=5508)\n",
    "training_df = training_df.drop(random_sample.index)\n",
    "\n",
    "\n",
    "print(training_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.277597900Z"
    },
    "id": "Wcd0bVSlDUdC"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "encodingTrainDFForDT = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_DT = encodingTrainDFForDT[['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly']]\n",
    "yTrain_DT = encodingTrainDFForDT['Churn']\n",
    "\n",
    "encodingTestDFForDT = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_DT = encodingTestDFForDT[['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly']]\n",
    "yTest_DT = encodingTestDFForDT['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.278598Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uo1Czb2q97ku",
    "outputId": "4cde143f-ea8b-463e-fac8-b5fe75e27fc4"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, roc_curve\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(XTrain_DT,yTrain_DT)\n",
    "yTrainPredicted_DT = DTclf.predict(XTrain_DT)\n",
    "yTestPredicted_DT = DTclf.predict(XTest_DT)\n",
    "print(f'DecisionTree Test accuracy {accuracy_score(yTest_DT,yTestPredicted_DT).__round__(5)}')\n",
    "# DecisionTreeClassifier\n",
    "# feature importance\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"feature\", \"Feature Importances\"]\n",
    "\n",
    "# featureImportances={}\n",
    "featureColumns= XTrain_DT.columns\n",
    "for i,j in enumerate(featureColumns):\n",
    "  table.add_row([j, DTclf.feature_importances_[i].round(5)])\n",
    "table.sortby = \"Feature Importances\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.279598500Z"
    },
    "id": "JGrvqI6cSBEp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.280598300Z"
    },
    "id": "POkNPDfCTGVF"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "newXTrain_DT= XTrain_DT.drop(['Contract_Length_Quarterly'],axis=1)\n",
    "newXTest_DT=XTest_DT.drop(['Contract_Length_Quarterly'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.281598300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTrHT7R7WcIZ",
    "outputId": "e0448f7c-6f85-41ab-edb4-ba255a25d83c"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(newXTrain_DT,yTrain_DT)\n",
    "yTrainPredicted_DT = DTclf.predict(newXTrain_DT)\n",
    "yTestPredicted_DT = DTclf.predict(newXTest_DT)\n",
    "print(f'DecisionTree Test accuracy {accuracy_score(yTest_DT,yTestPredicted_DT).__round__(5)}')\n",
    "# DecisionTreeClassifier\n",
    "# feature importance\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"feature\", \"Feature Importances\"]\n",
    "\n",
    "# featureImportances={}\n",
    "featureColumns= newXTrain_DT.columns\n",
    "for i,j in enumerate(featureColumns):\n",
    "  table.add_row([j, DTclf.feature_importances_[i].round(5)])\n",
    "table.sortby = \"Feature Importances\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.282598100Z"
    },
    "id": "ZSBTEmzdXDEc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.283598Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eAlFD5uXgbK",
    "outputId": "feee0706-1f86-4c88-f3eb-f31cb17cc6d7"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "newXTrain_DT= XTrain_DT.drop(['Contract_Length_Quarterly','Usage_Frequency'],axis=1)\n",
    "newXTest_DT=XTest_DT.drop(['Contract_Length_Quarterly','Usage_Frequency'],axis=1)\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(newXTrain_DT,yTrain_DT)\n",
    "yTrainPredicted_DT = DTclf.predict(newXTrain_DT)\n",
    "yTestPredicted_DT = DTclf.predict(newXTest_DT)\n",
    "print(f'DecisionTree Test accuracy {accuracy_score(yTest_DT,yTestPredicted_DT).__round__(5)}')\n",
    "# DecisionTreeClassifier\n",
    "# feature importance\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"feature\", \"Feature Importances\"]\n",
    "\n",
    "# featureImportances={}\n",
    "featureColumns= newXTrain_DT.columns\n",
    "for i,j in enumerate(featureColumns):\n",
    "  table.add_row([j, DTclf.feature_importances_[i].round(5)])\n",
    "table.sortby = \"Feature Importances\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.284598Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKtgIDywXpFW",
    "outputId": "051a3a8b-16ad-4607-fc1f-aa1d881b4f37"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "newXTrain_DT= XTrain_DT.drop(['Contract_Length_Quarterly','Usage_Frequency','Tenure'],axis=1)\n",
    "newXTest_DT=XTest_DT.drop(['Contract_Length_Quarterly','Usage_Frequency','Tenure'],axis=1)\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(newXTrain_DT,yTrain_DT)\n",
    "yTrainPredicted_DT = DTclf.predict(newXTrain_DT)\n",
    "yTestPredicted_DT = DTclf.predict(newXTest_DT)\n",
    "print(f'DecisionTree Test accuracy {accuracy_score(yTest_DT,yTestPredicted_DT).__round__(5)}')\n",
    "# DecisionTreeClassifier\n",
    "# feature importance\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"feature\", \"Feature Importances\"]\n",
    "\n",
    "# featureImportances={}\n",
    "featureColumns= newXTrain_DT.columns\n",
    "for i,j in enumerate(featureColumns):\n",
    "  table.add_row([j, DTclf.feature_importances_[i].round(5)])\n",
    "table.sortby = \"Feature Importances\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.285598100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrXu7qhaX1cn",
    "outputId": "88417bde-833d-462d-ad21-dc1226745e58"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "newXTrain_DT= XTrain_DT.drop(['Contract_Length_Quarterly','Usage_Frequency','Tenure','Subscription_Type_Premium'],axis=1)\n",
    "newXTest_DT=XTest_DT.drop(['Contract_Length_Quarterly','Usage_Frequency','Tenure','Subscription_Type_Premium'],axis=1)\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(newXTrain_DT,yTrain_DT)\n",
    "yTrainPredicted_DT = DTclf.predict(newXTrain_DT)\n",
    "yTestPredicted_DT = DTclf.predict(newXTest_DT)\n",
    "print(f'DecisionTree Test accuracy {accuracy_score(yTest_DT,yTestPredicted_DT).__round__(5)}')\n",
    "# DecisionTreeClassifier\n",
    "# feature importance\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"feature\", \"Feature Importances\"]\n",
    "\n",
    "# featureImportances={}\n",
    "featureColumns= newXTrain_DT.columns\n",
    "for i,j in enumerate(featureColumns):\n",
    "  table.add_row([j, DTclf.feature_importances_[i].round(5)])\n",
    "table.sortby = \"Feature Importances\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T23:05:52.353597900Z",
     "start_time": "2023-11-26T23:05:52.286598100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qY_-ZsmBY__Y",
    "outputId": "3db1c7c5-3cdb-41a3-e0d9-ae132abce0cf"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Pre-Pruned\n",
    "newXTrain_DT= XTrain_DT.drop(['Contract_Length_Quarterly','Usage_Frequency','Tenure','Subscription_Type_Premium','Subscription_Type_Standard'],axis=1)\n",
    "newXTest_DT=XTest_DT.drop(['Contract_Length_Quarterly','Usage_Frequency','Tenure','Subscription_Type_Premium','Subscription_Type_Standard'],axis=1)\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(newXTrain_DT,yTrain_DT)\n",
    "yTrainPredicted_DT = DTclf.predict(newXTrain_DT)\n",
    "yTestPredicted_DT = DTclf.predict(newXTest_DT)\n",
    "print(f'DecisionTree Test accuracy {accuracy_score(yTest_DT,yTestPredicted_DT).__round__(5)}')\n",
    "# DecisionTreeClassifier\n",
    "# feature importance\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"feature\", \"Feature Importances\"]\n",
    "\n",
    "# featureImportances={}\n",
    "featureColumns= newXTrain_DT.columns\n",
    "for i,j in enumerate(featureColumns):\n",
    "  table.add_row([j, DTclf.feature_importances_[i].round(5)])\n",
    "table.sortby = \"Feature Importances\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.286598100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5bdRLvRZPwv",
    "outputId": "e0be9267-6a09-4e21-e934-523bbdea8c8e"
   },
   "outputs": [],
   "source": [
    "print('Hence feature to removed from Decision tree classifier are:- Contract_Length_Quarterly ,Usage_Frequency, Tenure, Subscription_Type_Premium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.287598400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viNQ0x47auUM",
    "outputId": "51453423-a4fd-47f3-e33e-486c6955505a"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Pre-Pruned\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tuned_parameters = {\n",
    "'max_depth': [20], #[None, 5, 10, 20]\n",
    "'min_samples_split': [2], #[2, 5, 10]\n",
    "'min_samples_leaf': [3], #[1, 2,3,4]\n",
    "'max_features': ['sqrt'], #['auto', 'sqrt', 'log']\n",
    "'splitter': ['best'], #['best', 'random']\n",
    "'criterion': ['entropy'] #['gini', 'entropy','log_loss']\n",
    "}\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "gridSearch = GridSearchCV(DTclf, tuned_parameters)\n",
    "gridSearch.fit(XTrain_DT, yTrain_DT)\n",
    "print(\"Best parameters found: \", gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.288598400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "821ry6hYcZRQ",
    "outputId": "058fcadc-390e-42a6-d117-1f42492794ef"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Pre-Pruned\n",
    "gridSearch.best_estimator_.fit(XTrain_DT, yTrain_DT)\n",
    "yTestProbPrePruned= gridSearch.best_estimator_.predict_proba(XTest_DT)[::, -1]\n",
    "yTestPredPrePruned = gridSearch.best_estimator_.predict(XTest_DT)\n",
    "prePrunedAccuracy= accuracy_score(yTest_DT, yTestPredPrePruned)\n",
    "print(f'Pre-Pruned Test accuracy {prePrunedAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.289598400Z"
    },
    "id": "5iPpiWFiviB1"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Post-Pruned\n",
    "DTclf = DecisionTreeClassifier(random_state=5805)\n",
    "DTclf.fit(XTrain_DT,yTrain_DT)\n",
    "\n",
    "cpppath = DTclf.cost_complexity_pruning_path(XTrain_DT,yTrain_DT)\n",
    "alphas = cpppath['ccp_alphas']\n",
    "# Grid search for best alpha\n",
    "postPrunAccuracyTrain, postPrunAccuracyTest = [],[]\n",
    "for i in alphas:\n",
    "    DTclf = DecisionTreeClassifier(random_state=5805,ccp_alpha=i)\n",
    "    DTclf.fit(XTrain_DT,yTrain_DT)\n",
    "    yTrainPredPostPruned = DTclf.predict(XTrain_DT)\n",
    "    postPrunAccuracyTrain.append(accuracy_score(yTrain_DT, yTrainPredPostPruned))\n",
    "    yTestPredPostPruned = DTclf.predict(XTest_DT)\n",
    "    postPrunAccuracyTest.append(accuracy_score(yTest_DT, yTestPredPostPruned))\n",
    "print(f'alpha={alphas[postPrunAccuracyTest.index(max(postPrunAccuracyTest))].round(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.290598100Z"
    },
    "id": "r89C2HtHwC0g"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Post-Pruned\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title(\"Alpha for training and testing sets VS Accuracy\")\n",
    "ax.plot(alphas, postPrunAccuracyTrain, label=\"Train\", drawstyle=\"steps-post\")\n",
    "ax.plot(alphas, postPrunAccuracyTest, label=\"Test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.290598100Z"
    },
    "id": "hlvj__IGyqjp"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Post-Pruned\n",
    "DTclf = DecisionTreeClassifier(random_state=5805, ccp_alpha=alphas[postPrunAccuracyTest.index(max(postPrunAccuracyTest))].round(5))\n",
    "DTclf.fit(XTrain_DT, yTrain_DT)\n",
    "yTrainPredPostPruned = DTclf.predict(XTrain_DT)\n",
    "yTestPredPostPruned = DTclf.predict(XTest_DT)\n",
    "yTestProbPostPruned= DTclf.predict_proba(XTest_DT)[::, -1]\n",
    "postrePrunedAccuracy= accuracy_score(yTest_DT, yTestPredPostPruned)\n",
    "postrePrunedAccuracy_train= accuracy_score(yTrain_DT, yTrainPredPostPruned)\n",
    "print(f'Post-Pruned Test accuracy {accuracy_score(yTest_DT, yTestPredPostPruned).__round__(2)}')\n",
    "print(f'Post-Pruned Train accuracy {accuracy_score(yTrain_DT, yTrainPredPostPruned).__round__(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.291598100Z"
    },
    "id": "ozsXFwX52hxH"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Post-Pruned\n",
    "for key, value in DTclf.get_params().items():\n",
    "  print(f\"{key}: {value}\")\n",
    "\n",
    "confusionMatrixPrePruned = confusion_matrix(yTest_DT, yTestPredPrePruned)\n",
    "confusionMatrixPostPruned = confusion_matrix(yTest_DT, yTestPredPostPruned)\n",
    "recallPrePruned = recall_score(yTest_DT, yTestPredPrePruned)\n",
    "recallPostPruned = recall_score(yTest_DT, yTestPredPostPruned)\n",
    "rocAucPrePruned = roc_auc_score(yTest_DT, yTestProbPrePruned)\n",
    "rocAucPostPruned = roc_auc_score(yTest_DT, yTestProbPostPruned)\n",
    "\n",
    "table1 = PrettyTable()\n",
    "table1.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table1.add_row([\"Pre-Pruned\",prePrunedAccuracy.round(2),confusionMatrixPrePruned,recallPrePruned.round(2),rocAucPrePruned.round(2)])\n",
    "table1.add_row([\"Post-Pruned\",postrePrunedAccuracy.round(2),confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.293598500Z"
    },
    "id": "hvbtRB4b5vJ2"
   },
   "outputs": [],
   "source": [
    "# Post-Pruned\n",
    "fprPrePrunedtree, tprPrePrunedtree, _ = roc_curve(yTest_DT, yTestProbPrePruned)\n",
    "fprPostPrunedtree, tprPostPrunedtree, _ = roc_curve(yTest_DT,yTestProbPostPruned)\n",
    "plt.plot(fprPrePrunedtree, tprPrePrunedtree, label='Pre-Pruned')\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree, label='Post-Pruned')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('8.ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.294598500Z"
    },
    "id": "NcV5dMFUwhHI"
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "#remove  'Contract_Length_Quarterly','Usage_Frequency','Tenure','Subscription_Type_Premium\n",
    "removefeature= []\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "encodingTrainDFForLR = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_LR = encodingTrainDFForLR[finalFeature]\n",
    "yTrain_LR = encodingTrainDFForLR['Churn']\n",
    "\n",
    "encodingTestDFForLR = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_LR = encodingTestDFForLR[finalFeature]\n",
    "yTest_LR = encodingTestDFForLR['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.295598100Z"
    },
    "id": "-iIgsN3heGh9"
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "logregclf = LogisticRegression()\n",
    "logregclf.fit(XTrain_LR, yTrain_LR)\n",
    "logregYTestPred = logregclf.predict(XTest_LR)\n",
    "logregAccuracy = accuracy_score(yTest_LR, logregYTestPred)\n",
    "yTestProbLogreg= logregclf.predict_proba(XTest_LR)[::, -1]\n",
    "print(f'Logistic regression Accuracy = {logregAccuracy.__round__(5)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.296597900Z"
    },
    "id": "RmBFCjLt-gLY"
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "confusionMatrixlogreg = confusion_matrix(yTest_LR, logregYTestPred)\n",
    "recallLogreg = recall_score(yTest_LR, logregYTestPred)\n",
    "rocAucLogreg = roc_auc_score(yTest_LR, yTestProbLogreg)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "print(table2)\n",
    "\n",
    "fprlogregclf, tprlogregclf, _ = roc_curve(yTest_LR, yTestProbLogreg)\n",
    "# ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree,  label='Decision tree-Post-Pruned')\n",
    "plt.plot(fprlogregclf, tprlogregclf, label='Logistic regression')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random selection')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.297597900Z"
    },
    "id": "QqS6p84b-ih1"
   },
   "outputs": [],
   "source": [
    "# svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "encodingTrainDFForSVM = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTrainDfSVM= Standardized(encodingTrainDFForSVM[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTrainDfSVM=pd.concat([standardizedTrainDfSVM,encodingTrainDFForSVM[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_SVM = standardizedTrainDfSVM\n",
    "yTrain_SVM = encodingTrainDFForSVM['Churn']\n",
    "\n",
    "encodingTestDFForSVM = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTestDfSVM= Standardized(encodingTestDFForSVM[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTestDfSVM=pd.concat([standardizedTestDfSVM,encodingTestDFForSVM[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "\n",
    "XTest_SVM = standardizedTestDfSVM\n",
    "yTest_SVM = encodingTestDFForSVM['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.298597900Z"
    },
    "id": "hHQ-PJtBIUeW"
   },
   "outputs": [],
   "source": [
    "# #SVM\n",
    "# from sklearn.svm import SVC\n",
    "# svm_model = SVC()\n",
    "# param_grid = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "# \n",
    "# grid_search = GridSearchCV(svm_model, param_grid, scoring='accuracy')\n",
    "# grid_search.fit(XTrain_SVM, yTrain_SVM)\n",
    "# \n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.299598700Z"
    },
    "id": "nuRqudy1TXTX"
   },
   "outputs": [],
   "source": [
    "# svm\n",
    "from sklearn.svm import SVC\n",
    "svmclf = SVC(kernel='linear', C=10,probability=True)\n",
    "svmclf.fit(XTrain_SVM, yTrain_SVM)\n",
    "svmYTestPred = svmclf.predict(XTest_SVM)\n",
    "svmAccuracy = accuracy_score(yTest_SVM, svmYTestPred)\n",
    "\n",
    "print(f'SVM Accuracy = {svmAccuracy.__round__(5)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.300598200Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "svmAccuracy=accuracy_score(yTest_SVM, svmYTestPred)\n",
    "print(f'SVM Accuracy = {svmAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.301597900Z"
    }
   },
   "outputs": [],
   "source": [
    "yTestProbsvm= svmclf.predict_proba(XTest_SVM)[::, -1]\n",
    "confusionMatrixsvm = confusion_matrix(yTest_SVM, svmYTestPred)\n",
    "recallsvm = recall_score(yTest_SVM, svmYTestPred)\n",
    "rocAucsvm = roc_auc_score(yTest_SVM, yTestProbsvm)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "table2.add_row([\"SVM\",svmAccuracy.round(2),confusionMatrixsvm.round(2),recallsvm.round(2),rocAucsvm.round(2)])\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.302597900Z"
    },
    "id": "ushOz18kV_s4"
   },
   "outputs": [],
   "source": [
    "# svm\n",
    "fprsvm, tprsvm, _ = roc_curve(yTest_SVM, yTestProbsvm)\n",
    "# ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree,  label='Decision tree-Post-Pruned')\n",
    "plt.plot(fprlogregclf, tprlogregclf, label='Logistic regression')\n",
    "plt.plot(fprsvm, tprsvm, label='SVM')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random selection')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.302597900Z"
    },
    "id": "spPTt_J_gZqL"
   },
   "outputs": [],
   "source": [
    "# Nave Bayes\n",
    "#remove  'Contract_Length_Quarterly','Usage_Frequency','Tenure','Subscription_Type_Premium\n",
    "removefeature= []\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "\n",
    "encodingTrainDFForNB = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_NB = encodingTrainDFForNB[finalFeature]\n",
    "yTrain_NB = encodingTrainDFForNB['Churn']\n",
    "\n",
    "encodingTestDFForNB = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_NB = encodingTestDFForNB[finalFeature]\n",
    "yTest_NB = encodingTestDFForNB['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.303598Z"
    },
    "id": "tidqejC4wEYo"
   },
   "outputs": [],
   "source": [
    "# Nave Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbclf = GaussianNB()\n",
    "nbclf.fit(XTrain_NB, yTrain_NB)\n",
    "nbYTestPred = nbclf.predict(XTest_NB)\n",
    "nbAccuracy = accuracy_score(yTest_NB, nbYTestPred)\n",
    "yTestProbnb= nbclf.predict_proba(XTest_NB)[::, -1]\n",
    "print(f'Nave Bayes = {nbAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.304598100Z"
    },
    "id": "TNBaAoe2xMmB"
   },
   "outputs": [],
   "source": [
    "# Nave Bayes\n",
    "confusionMatrixnb = confusion_matrix(yTest_NB, nbYTestPred)\n",
    "recallnb = recall_score(yTest_NB, nbYTestPred)\n",
    "rocAucnb = roc_auc_score(yTest_NB, yTestProbnb)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "table2.add_row([\"SVM\",svmAccuracy.round(2),confusionMatrixsvm.round(2),recallsvm.round(2),rocAucsvm.round(2)])\n",
    "table2.add_row([\"Nave Bayes\",nbAccuracy.round(2),confusionMatrixnb.round(2),recallnb.round(2),rocAucnb.round(2)])\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.304598100Z"
    },
    "id": "DH3JR-tSx5K3"
   },
   "outputs": [],
   "source": [
    "# Nave Bayes\n",
    "fprnb, tprnb, _ = roc_curve(yTest_NB, yTestProbnb)\n",
    "# ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree,  label='Decision tree-Post-Pruned')\n",
    "plt.plot(fprlogregclf, tprlogregclf, label='Logistic regression')\n",
    "plt.plot(fprsvm, tprsvm, label='SVM')\n",
    "plt.plot(fprnb, tprnb, label='Nave Bayes')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random selection')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.305598200Z"
    },
    "id": "1H6l85aH2fpm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.306598Z"
    },
    "id": "xS2PadLn3PH7"
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "encodingTrainDFForKNN = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTrainDfKNN= Standardized(encodingTrainDFForKNN[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTrainDfKNN=pd.concat([standardizedTrainDfKNN,encodingTrainDFForKNN[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_KNN = standardizedTrainDfKNN\n",
    "yTrain_KNN = encodingTrainDFForKNN['Churn']\n",
    "\n",
    "encodingTestDFForKNN = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTestDfKNN= Standardized(encodingTestDFForKNN[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTestDfKNN = pd.concat([standardizedTestDfKNN,encodingTestDFForKNN[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "\n",
    "XTest_KNN = standardizedTestDfKNN\n",
    "yTest_KNN = encodingTestDFForKNN['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.306598Z"
    },
    "id": "oNEEZC7q4OJD"
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rates = []\n",
    "k_values = range(1, 40)\n",
    "\n",
    "for k in k_values:\n",
    "    knnclf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnclf.fit(XTrain_KNN, yTrain_KNN)\n",
    "    knnYTestPred = knnclf.predict(XTest_KNN)\n",
    "    error_rates.append(1 - accuracy_score(yTest_KNN, knnYTestPred))\n",
    "\n",
    "\n",
    "plt.plot(k_values, error_rates, marker='o')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.307598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knnclf = KNeighborsClassifier(n_neighbors=25)\n",
    "knnclf.fit(XTrain_KNN, yTrain_KNN)\n",
    "knnYTestPred = knnclf.predict(XTest_KNN)\n",
    "knnAccuracy= accuracy_score(yTest_KNN, knnYTestPred)\n",
    "print(knnAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.308598300Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "yTestProbknn= knnclf.predict_proba(XTest_KNN)[::, -1]\n",
    "confusionMatrixknn = confusion_matrix(yTest_KNN, knnYTestPred)\n",
    "recallknn = recall_score(yTest_KNN, knnYTestPred)\n",
    "rocAucknn = roc_auc_score(yTest_KNN, yTestProbknn)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "table2.add_row([\"SVM\",svmAccuracy.round(2),confusionMatrixsvm.round(2),recallsvm.round(2),rocAucsvm.round(2)])\n",
    "table2.add_row([\"Nave Bayes\",nbAccuracy.round(2),confusionMatrixnb.round(2),recallnb.round(2),rocAucnb.round(2)])\n",
    "table2.add_row([\"KNN\",knnAccuracy.round(2),confusionMatrixknn.round(2),recallknn.round(2),rocAucknn.round(2)])\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.308598300Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "fprknn, tprknn, _ = roc_curve(yTest_KNN, yTestProbknn)\n",
    "# ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree,  label='Decision tree-Post-Pruned')\n",
    "plt.plot(fprlogregclf, tprlogregclf, label='Logistic regression')\n",
    "plt.plot(fprsvm, tprsvm, label='SVM')\n",
    "plt.plot(fprnb, tprnb, label='Nave Bayes')\n",
    "plt.plot(fprknn, tprknn, label='KNN')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random selection')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.309597900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "\n",
    "encodingTrainDFForRF = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_RF = encodingTrainDFForRF[finalFeature]\n",
    "yTrain_RF = encodingTrainDFForRF['Churn']\n",
    "\n",
    "encodingTestDFForRF = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_RF = encodingTestDFForRF[finalFeature]\n",
    "yTest_RF = encodingTestDFForRF['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.310598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rfclf = RandomForestClassifier(n_estimators=100, random_state=5805)\n",
    "rfclf.fit(XTrain_RF, yTrain_RF)\n",
    "rfYTestPred = rfclf.predict(XTest_RF)\n",
    "rfAccuracy = accuracy_score(yTest_RF, rfYTestPred)\n",
    "yTestProbrf= nbclf.predict_proba(XTest_RF)[::, -1]\n",
    "print(f'Random Forest = {rfAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.310598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "yTestProbrf= rfclf.predict_proba(XTest_RF)[::, -1]\n",
    "confusionMatrixrf = confusion_matrix(yTest_RF, rfYTestPred)\n",
    "recallrf = recall_score(yTest_RF, rfYTestPred)\n",
    "rocAucrf = roc_auc_score(yTest_RF, yTestProbrf)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "table2.add_row([\"SVM\",svmAccuracy.round(2),confusionMatrixsvm.round(2),recallsvm.round(2),rocAucsvm.round(2)])\n",
    "table2.add_row([\"Nave Bayes\",nbAccuracy.round(2),confusionMatrixnb.round(2),recallnb.round(2),rocAucnb.round(2)])\n",
    "table2.add_row([\"KNN\",knnAccuracy.round(2),confusionMatrixknn.round(2),recallknn.round(2),rocAucknn.round(2)])\n",
    "table2.add_row([\"RF\",rfAccuracy.round(2),confusionMatrixrf.round(2),recallrf.round(2),rocAucrf.round(2)])\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.311598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "fprrf, tprrf, _ = roc_curve(yTest_RF, yTestProbrf)\n",
    "# ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree,  label='Decision tree-Post-Pruned')\n",
    "plt.plot(fprlogregclf, tprlogregclf, label='Logistic regression')\n",
    "plt.plot(fprsvm, tprsvm, label='SVM')\n",
    "plt.plot(fprnb, tprnb, label='Nave Bayes')\n",
    "plt.plot(fprknn, tprknn, label='KNN')\n",
    "plt.plot(fprrf, tprrf, label='Random Forest')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random selection')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.312598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "\n",
    "encodingTrainDFForBA = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_BA = encodingTrainDFForBA[finalFeature]\n",
    "yTrain_BA = encodingTrainDFForBA['Churn']\n",
    "\n",
    "encodingTestDFForBA = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_BA = encodingTestDFForBA[finalFeature]\n",
    "yTest_BA = encodingTestDFForBA['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.312598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "baclf = BaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=100),\n",
    "                                  n_estimators=10, random_state=5805)\n",
    "\n",
    "baclf.fit(XTrain_BA, yTrain_BA)\n",
    "baYTestPred = baclf.predict(XTest_BA)\n",
    "baAccuracy = accuracy_score(yTest_BA, baYTestPred)\n",
    "yTestProbba= nbclf.predict_proba(XTest_BA)[::, -1]\n",
    "print(f'Random Forest = {baAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.313598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "yTestProbba= baclf.predict_proba(XTest_BA)[::, -1]\n",
    "confusionMatrixba = confusion_matrix(yTest_BA, baYTestPred)\n",
    "recallba = recall_score(yTest_BA, baYTestPred)\n",
    "rocAucba = roc_auc_score(yTest_BA, yTestProbba)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "table2.add_row([\"SVM\",svmAccuracy.round(2),confusionMatrixsvm.round(2),recallsvm.round(2),rocAucsvm.round(2)])\n",
    "table2.add_row([\"Nave Bayes\",nbAccuracy.round(2),confusionMatrixnb.round(2),recallnb.round(2),rocAucnb.round(2)])\n",
    "table2.add_row([\"KNN\",knnAccuracy.round(2),confusionMatrixknn.round(2),recallknn.round(2),rocAucknn.round(2)])\n",
    "table2.add_row([\"RF\",rfAccuracy.round(2),confusionMatrixrf.round(2),recallrf.round(2),rocAucrf.round(2)])\n",
    "table2.add_row([\"Bagging\",baAccuracy.round(2),confusionMatrixba.round(2),recallba.round(2),rocAucba.round(2)])\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.314597600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "fprba, tprba, _ = roc_curve(yTest_BA, yTestProbba)\n",
    "# ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprPostPrunedtree, tprPostPrunedtree,  label='Decision tree-Post-Pruned')\n",
    "plt.plot(fprlogregclf, tprlogregclf, label='Logistic regression')\n",
    "plt.plot(fprsvm, tprsvm, label='SVM')\n",
    "plt.plot(fprnb, tprnb, label='Nave Bayes')\n",
    "plt.plot(fprknn, tprknn, label='KNN')\n",
    "plt.plot(fprrf, tprrf, label='Random Forest')\n",
    "plt.plot(fprba, tprba, label='Bagging')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random selection')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.314597600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "\n",
    "encodingTrainDFForST = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_ST = encodingTrainDFForST[finalFeature]\n",
    "yTrain_ST = encodingTrainDFForST['Churn']\n",
    "\n",
    "encodingTestDFForST = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_ST = encodingTestDFForST[finalFeature]\n",
    "yTest_ST = encodingTestDFForST['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.315598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_estimators = [('rf', RandomForestClassifier(n_estimators=100, random_state=5805)),]\n",
    "meta_estimator = LogisticRegression()\n",
    "\n",
    "stclf = StackingClassifier(estimators=base_estimators, final_estimator=meta_estimator)\n",
    "stclf.fit(XTrain_ST, yTrain_ST)\n",
    "\n",
    "stYTestPred = stclf.predict(XTest_ST)\n",
    "stAccuracy = accuracy_score(yTest_ST, stYTestPred)\n",
    "print(f'Random Forest = {stAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.315598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stacking\n",
    "yTestProbst= stclf.predict_proba(XTest_ST)[::, -1]\n",
    "confusionMatrixst = confusion_matrix(yTest_ST, stYTestPred)\n",
    "recallst = recall_score(yTest_ST, stYTestPred)\n",
    "rocAucst = roc_auc_score(yTest_ST, yTestProbst)\n",
    "\n",
    "fprst, tprst, _ = roc_curve(yTest_ST, yTestProbst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.316597800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Boosting\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "\n",
    "encodingTrainDFForBOO = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_BOO = encodingTrainDFForBOO[finalFeature]\n",
    "yTrain_BOO = encodingTrainDFForBOO['Churn']\n",
    "\n",
    "encodingTestDFForBOO = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "XTest_BOO = encodingTestDFForBOO[finalFeature]\n",
    "yTest_BOO = encodingTestDFForBOO['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.317598100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "booclf = GradientBoostingClassifier(n_estimators=100, random_state=5805)\n",
    "booclf.fit(XTrain_BOO, yTrain_BOO)\n",
    "\n",
    "booYTestPred = booclf.predict(XTest_BOO)\n",
    "booAccuracy = accuracy_score(yTest_BOO, booYTestPred)\n",
    "print(f'Boosting = {booAccuracy.__round__(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.317598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Boosting\n",
    "yTestProbboo= booclf.predict_proba(XTest_BOO)[::, -1]\n",
    "confusionMatrixboo = confusion_matrix(yTest_BOO, booYTestPred)\n",
    "recallboo = recall_score(yTest_BOO, booYTestPred)\n",
    "rocAucboo = roc_auc_score(yTest_BOO, yTestProbboo)\n",
    "\n",
    "fprboo, tprboo, _ = roc_curve(yTest_BOO, yTestProbboo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.318598200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "encodingTrainDFForNN = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTrainDfNN= Standardized(encodingTrainDFForNN[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTrainDfNN=pd.concat([standardizedTrainDfNN,encodingTrainDFForNN[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "# encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "XTrain_NN = standardizedTrainDfNN\n",
    "yTrain_NN = encodingTrainDFForNN['Churn']\n",
    "\n",
    "encodingTestDFForNN = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "standardizedTestDfNN= Standardized(encodingTestDFForNN[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']])\n",
    "standardizedTestDfNN = pd.concat([standardizedTestDfNN,encodingTestDFForNN[['Gender_Male','Subscription_Type_Premium','Subscription_Type_Standard','Contract_Length_Monthly','Contract_Length_Quarterly']]], axis=1)\n",
    "\n",
    "XTest_NN = standardizedTestDfNN\n",
    "yTest_NN = encodingTestDFForNN['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.319598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nnclf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=5805)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=5805)\n",
    "nnYTestPred = cross_val_predict(nnclf, XTest_NN, yTest_NN, cv=cv,method='predict_proba')\n",
    "\n",
    "nnAccuracy = accuracy_score(yTest_NN, nnYTestPred.argmax(axis=1))\n",
    "print(f'Boosting = {nnAccuracy.__round__(5)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.319598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "# yTestProbboo= booclf.predict_proba(XTest_BOO)[::, -1]\n",
    "confusionMatrixnn = confusion_matrix(yTest_NN, nnYTestPred.argmax(axis=1))\n",
    "recallnn = recall_score(yTest_NN, nnYTestPred.argmax(axis=1))\n",
    "rocAucnn = roc_auc_score(yTest_NN, nnYTestPred[:, 1])\n",
    "\n",
    "fprnn, tprnn, _ = roc_curve(yTest_NN, nnYTestPred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.320598100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "yTestProbba= baclf.predict_proba(XTest_BA)[::, -1]\n",
    "confusionMatrixba = confusion_matrix(yTest_BA, baYTestPred)\n",
    "recallba = recall_score(yTest_BA, baYTestPred)\n",
    "rocAucba = roc_auc_score(yTest_BA, yTestProbba)\n",
    "\n",
    "table2 = PrettyTable()\n",
    "table2.field_names = [\"\",\"Accuracy\", \"confusion Matrix\", \"recall\", 'AUC']\n",
    "table2.add_row([\"Decision Tree Post-Pruned\",postrePrunedAccuracy.round(2), confusionMatrixPostPruned,recallPostPruned.round(2),rocAucPostPruned.round(2)])\n",
    "table2.add_row([\"logistic regression\",logregAccuracy.round(2),confusionMatrixlogreg.round(2),recallLogreg.round(2),rocAucLogreg.round(2)])\n",
    "table2.add_row([\"SVM\",svmAccuracy.round(2),confusionMatrixsvm.round(2),recallsvm.round(2),rocAucsvm.round(2)])\n",
    "table2.add_row([\"Nave Bayes\",nbAccuracy.round(2),confusionMatrixnb.round(2),recallnb.round(2),rocAucnb.round(2)])\n",
    "table2.add_row([\"KNN\",knnAccuracy.round(2),confusionMatrixknn.round(2),recallknn.round(2),rocAucknn.round(2)])\n",
    "table2.add_row([\"RF\",rfAccuracy.round(2),confusionMatrixrf.round(2),recallrf.round(2),rocAucrf.round(2)])\n",
    "table2.add_row([\"Bagging\",baAccuracy.round(2),confusionMatrixba.round(2),recallba.round(2),rocAucba.round(2)])\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.321597900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Phase IV: Clustering and Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.321597900Z"
    }
   },
   "outputs": [],
   "source": [
    "#K-mean\n",
    "removefeature=[]\n",
    "finalFeature= [item for item in ['Age', 'Tenure', 'Usage_Frequency', 'Support_Calls', 'Payment_Delay',\n",
    "       'Total_Spend', 'Last_Interaction', 'Gender_Male',\n",
    "       'Subscription_Type_Premium', 'Subscription_Type_Standard',\n",
    "       'Contract_Length_Monthly', 'Contract_Length_Quarterly'] if item not in removefeature]\n",
    "\n",
    "\n",
    "\n",
    "XCat_KM=  training_df[['Gender', 'Subscription_Type', 'Contract_Length']]\n",
    "XNum_KM= training_df[['Age','Tenure','Usage_Frequency','Support_Calls','Payment_Delay','Total_Spend','Last_Interaction']]\n",
    "\n",
    "# encodingTrainDFForBOO = pd.get_dummies(training_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# # encodingTrainDFForDT = encodingTrainDFForDT.drop(columns=['Contract_Length_Quarterly', 'Usage_Frequency', 'Subscription_Type_Premium', 'Subscription_Type_Standard'])\n",
    "# XTrain_\n",
    "# XTrain_BOO = encodingTrainDFForBOO[finalFeature]\n",
    "# yTrain_BOO = encodingTrainDFForBOO['Churn']\n",
    "# \n",
    "# encodingTestDFForBOO = pd.get_dummies(testing_df, columns=['Gender', 'Subscription_Type', 'Contract_Length'],drop_first=True)\n",
    "# XTest_BOO = encodingTestDFForBOO[finalFeature]\n",
    "# yTest_BOO = encodingTestDFForBOO['Churn']\n",
    "\n",
    "print(training_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.322597900Z"
    }
   },
   "outputs": [],
   "source": [
    "#K-mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# numerical_features = XNum_KM\n",
    "# categorical_features = XCat_KM\n",
    "\n",
    "all_features = pd.concat([XNum_KM, XCat_KM], axis=1)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# numerical_features_scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, XNum_KM.columns),\n",
    "        ('cat', 'passthrough', XCat_KM.columns)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('kmeans', KModes(n_clusters=3, init='Huang', n_init=5, verbose=1))\n",
    "])\n",
    "\n",
    "pipeline.fit(all_features)\n",
    "\n",
    "# training_df['cluster'] = pipeline.named_steps['kmeans'].labels_\n",
    "\n",
    "# Assign cluster labels to the original data\n",
    "# cluster = pd.Series(pipeline.named_steps['kmeans'].labels_)\n",
    "# \n",
    "# # Visualize the clusters\n",
    "# cluster_size = cluster.value_counts()\n",
    "# plt.bar(cluster_size.index, cluster_size.values)\n",
    "# plt.xlabel('Cluster')\n",
    "# plt.ylabel('Number of Samples')\n",
    "# plt.title('Cluster Sizes')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.322597900Z"
    }
   },
   "outputs": [],
   "source": [
    "#K-mean\n",
    "cluster = pd.Series(pipeline.named_steps['kmeans'].labels_)\n",
    "\n",
    "# Visualize the clusters\n",
    "cluster_size = cluster.value_counts()\n",
    "plt.bar(cluster_size.index, cluster_size.values)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Cluster Sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.323598200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.324598200Z"
    }
   },
   "outputs": [],
   "source": [
    "#K-mean\n",
    "cluster_sizes = [50, 30, 20]\n",
    "\n",
    "# Assuming 'cluster_series' is the Pandas Series containing cluster labels\n",
    "cluster_counts = cluster.value_counts()\n",
    "\n",
    "# Plotting a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(cluster_counts, labels=cluster_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Cluster Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.325597900Z"
    }
   },
   "outputs": [],
   "source": [
    "#K-mean\n",
    "print('The sizes of the clusters are imbalanced, with the 0th cluster having the largest number of observations (175,000), followed by the 1st cluster (108,000) and the 2nd cluster (90,000) \\nThe 0th cluster is significantly larger than the other clusters, suggesting that it might represent a more dominant or prevalent group in the dataset.\\nThe large size of the dominant cluster could pose challenges in terms of interpretability. It might be more challenging to distinguish unique patterns within this cluster due to its size\\nThe presence of multiple clusters indicates that there are distinct subgroups in the data. Each cluster may represent a different pattern or behavior among the observations\\nThe results of association rule mining would depend on the specific features used and the relationships explored. The imbalanced cluster sizes may influence the rules generated, and its essential to consider the context of the analysis\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.325597900Z"
    }
   },
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load Titanic dataset\n",
    "# titanic_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Select features for clustering (both numerical and categorical)\n",
    "numerical_features = XNum_KM\n",
    "categorical_features = XCat_KM\n",
    "\n",
    "# Define preprocessing steps for numerical features\n",
    "numerical_preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define preprocessing steps for categorical features\n",
    "categorical_preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combine numerical and categorical preprocessing using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_preprocessor, numerical_features.columns),\n",
    "        ('cat', categorical_preprocessor, categorical_features.columns)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing and DBSCAN\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('dbscan', DBSCAN(eps=0.5, min_samples=5))  # Adjust parameters accordingly\n",
    "])\n",
    "all_features = pd.concat([XNum_KM, XCat_KM], axis=1)\n",
    "\n",
    "# Fit the model\n",
    "labels = pipeline.fit_predict(all_features)\n",
    "\n",
    "cluster_counts = pd.Series(labels).value_counts().sort_index()\n",
    "# Create a bar plot\n",
    "plt.bar(cluster_counts.index, cluster_counts.values)\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Number of Samples in Each Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T23:05:52.326598Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
